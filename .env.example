# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b

# Stack Overflow API (optional - for rate limiting)
SO_API_KEY=your_stack_overflow_api_key_here

# FastAPI Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=true

# Optional: MongoDB (if you want to add persistence later)
MONGODB_URI=mongodb://localhost:27017
DATABASE_NAME=llm_faq